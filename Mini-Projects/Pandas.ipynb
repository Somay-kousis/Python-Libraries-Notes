{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81d63b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb8130",
   "metadata": {},
   "source": [
    "## Pandas "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22df2e",
   "metadata": {},
   "source": [
    "#### **Question 1.1: The ML Dataset Preprocessor**\n",
    "\n",
    "**Scenario**: You just downloaded a messy dataset for your first ML project. It's exactly the kind of data you'll face in real ML work.\n",
    "\n",
    "**Your Mission**: Create a dataset with 1000 rows and these columns:\n",
    "\n",
    "- `customer_id`: 1 to 1000\n",
    "- `age`: random integers 18-80, but 50 values are missing (NaN)\n",
    "- `income`: random floats 20000-100000, but 30 values are negative (data errors)\n",
    "- `category`: random choice from ['A', 'B', 'C', 'D'], but 40 values are empty strings\n",
    "- `purchase_amount`: random floats 10-5000\n",
    "- `date`: random dates in 2023, but 25 dates are in wrong format (strings like \"2023/13/45\")\n",
    "\n",
    "**Detailed Question**: How do you clean this dataset to make it ML-ready? You need to:\n",
    "\n",
    "- Handle missing ages (should you drop, fill with mean, or median?)\n",
    "- Fix negative incomes (convert to positive or remove?)\n",
    "- Handle empty categories (fill with 'Unknown' or most frequent?)\n",
    "- Fix invalid dates (convert or remove?)\n",
    "- Create new features: age_group (Young/Middle/Senior), income_level (Low/Medium/High)\n",
    "\n",
    "**Hint**: Use `pd.DataFrame()` with random data, `np.nan`, `pd.to_datetime()`, `pd.cut()` for binning, and conditional logic for cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e4c4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"customer_id\" : np.arange(1,n+1),\n",
    "        \"age\" : np.random.randint(18,81,size=n),\n",
    "        \"income\" : np.random.uniform(20000.0,100000.0, size=n),\n",
    "        \"category\" : np.random.choice([\"A\",\"B\",\"C\",\"D\"], size=n),\n",
    "        \"purchase_amount\" : np.random.uniform(10.0,5000.0, size=n),\n",
    "        \"date\": pd.to_datetime(np.random.randint(\n",
    "        pd.Timestamp(\"2023-01-01\").value, \n",
    "        pd.Timestamp(\"2024-01-01\").value, \n",
    "        size=n)\n",
    "    )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d321551",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_age_indices = np.random.choice(n,size=50, replace=False) #replace one is only require to prevent repeat\n",
    "df.loc[missing_age_indices, 'age'] = np.nan\n",
    "\n",
    "negative_income_indices = np.random.choice(n,size=30, replace=False) \n",
    "df.loc[negative_income_indices, 'income'] = -1\n",
    "\n",
    "empty_string_indices = np.random.choice(n,size=40, replace = False)\n",
    "df.loc[empty_string_indices, 'category'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4caeeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = df[df['age'].notna()]\n",
    "m = sf['age'].mean()\n",
    "df['age'] = df['age'].fillna(value=m)\n",
    "\n",
    "df.loc[df['income'] < 0, 'income'] = np.nan\n",
    "df = df[df['income'].notna()]\n",
    "\n",
    "freq = df[\"category\"].value_counts().idxmax()\n",
    "df.loc[df['category'] == \"\", 'category'] = freq\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfe1a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins1 = [18,30,55,80]\n",
    "bins2 = [20000,45000,70000,100000]\n",
    "\n",
    "labels1 = [\"Young\", \"Middle\", \"Senior\"]\n",
    "labels2 = [\"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "age_groups = pd.cut(df['age'], bins=bins1, labels=labels1)\n",
    "income_level = pd.cut(df['income'], bins=bins2, labels=labels2)\n",
    "\n",
    "df[\"age_groups\"] = age_groups\n",
    "df[\"income_level\"] = income_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb2bcd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     customer_id   age        income category  purchase_amount  \\\n",
      "0              1  27.0  77057.425624        D       610.112747   \n",
      "1              2  69.0  89279.367991        B      3083.721170   \n",
      "2              3  71.0  71678.546157        D      3796.214683   \n",
      "3              4  67.0  91848.496448        A       222.834355   \n",
      "4              5  38.0  98014.377415        D      1573.337333   \n",
      "..           ...   ...           ...      ...              ...   \n",
      "995          996  61.0  67117.474695        B      2476.708899   \n",
      "996          997  74.0  99980.107224        B       770.726820   \n",
      "997          998  41.0  97314.696722        D      4904.127206   \n",
      "998          999  38.0  91718.167282        D        13.909988   \n",
      "999         1000  42.0  96180.616296        C        18.055443   \n",
      "\n",
      "                             date age_groups income_level  \n",
      "0   2023-01-06 02:05:35.032099792      Young         High  \n",
      "1   2023-09-15 02:05:12.742059989     Senior         High  \n",
      "2   2023-08-06 06:42:40.235508780     Senior         High  \n",
      "3   2023-08-05 17:02:04.604146222     Senior         High  \n",
      "4   2023-03-11 01:29:28.872806726     Middle         High  \n",
      "..                            ...        ...          ...  \n",
      "995 2023-02-09 15:10:09.314706872     Senior       Medium  \n",
      "996 2023-01-05 12:37:02.357515372     Senior         High  \n",
      "997 2023-06-14 14:49:37.768568455     Middle         High  \n",
      "998 2023-08-10 12:13:43.022241704     Middle         High  \n",
      "999 2023-08-05 11:31:32.989204972     Middle         High  \n",
      "\n",
      "[970 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33ea27",
   "metadata": {},
   "source": [
    "#### **Question 1.2: The Time Series Explorer**\n",
    "\n",
    "**Scenario**: You're analyzing user behavior data for an ML model that predicts user churn.\n",
    "\n",
    "**Create this dataset**:\n",
    "\n",
    "```python\n",
    "# 365 days of user activity data\n",
    "dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "users = ['user_' + str(i) for i in range(1, 101)]  # 100 users\n",
    "```\n",
    "\n",
    "**Detailed Question**: Generate a dataset where each user has daily activity data (login_count, session_duration, clicks). Then:\n",
    "\n",
    "- Find users with the highest average activity per month\n",
    "- Identify users who were active early in the year but stopped (potential churn)\n",
    "- Calculate 7-day and 30-day rolling averages for each user\n",
    "- Find the most active day of the week across all users\n",
    "- Create a \"user_risk_score\" based on recent activity decline\n",
    "\n",
    "**Hint**: Use `pd.MultiIndex`, `groupby()`, `rolling()`, `resample()`, and custom functions for risk calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0655046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('2023-01-01', '2023-12-31', freq='D')\n",
    "users = ['user_' + str(i) for i in range(1, 101)] \n",
    "arrays = [users,dates]\n",
    "index = pd.MultiIndex.from_product(arrays, names=[\"user\",\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "472eeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"Activity\": np.random.randint(1,16,size=36500)\n",
    "}, index=index).reset_index()\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "df['week'] = df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_avg = df.groupby(['user','month'])['Activity'].mean().reset_index()\n",
    "top_users = monthly_avg.loc[monthly_avg.groupby('month')['Activity'].idxmax()]\n",
    "\n",
    "last_active_date = df[df['Activity'] > 0].groupby('user')['date'].max().reset_index()\n",
    "churned_users = last_active_date[last_active_date['date'] < '2023-09-01']\n",
    "\n",
    "df = df.sort_values(['user', 'date'])\n",
    "df['rolling_7'] = df.groupby('user')['Activity'].transform(lambda x: x.rolling(7, min_periods=1).mean())\n",
    "df['rolling_30'] = df.groupby('user')['Activity'].transform(lambda x: x.rolling(30, min_periods=1).mean())\n",
    "\n",
    "df['day_name'] = df['date'].dt.day_name()\n",
    "weekday_avg = df.groupby('day_name')['Activity'].mean().sort_values(ascending=False)\n",
    "most_active_day = weekday_avg.idxmax()\n",
    "\n",
    "risk_scores = []\n",
    "for user in df['user'].unique():\n",
    "    user_df = df[df['user'] == user]\n",
    "    first_30 = user_df.head(30)['Activity'].mean()\n",
    "    last_30 = user_df.tail(30)['Activity'].mean() \n",
    "    score = last_30 / (first_30 + 1e-6)  # Add epsilon to avoid division by zero\n",
    "    risk_scores.append((user, score))\n",
    "risk_df = pd.DataFrame(risk_scores, columns=['user', 'user_risk_score'])\n",
    "# Sort: lowest score = highest risk\n",
    "risk_df = risk_df.sort_values('user_risk_score')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
